[{"id":"a99376fa230b8d8b33ec300ad3be8330","title":"What? Gemini demo video is a edited version","content":"The release of Gemini has taken the tech world by storm, appearing to overshadow GPT-4 and attracting widespread attention. Tech giant Google, parent company of Alphabet (Nasdaq: GOOG), experienced a 5.31% surge in its stock price on December 7th, closing at $136.93 per share. This marked its best performance since August 29th, pushing its total market value to $1.72 trillion. However, analysts suggest that Google may have engaged in exaggerated promotion tactics for Gemini.\nAccording to Google’s released data, Gemini Ultra is touted as the first large model to outperform human experts in the Massively Multitask Language Understanding (MMLU) task, achieving an impressive score of 90.0%. In comparison, human experts scored 89.8%, and GPT-4 scored 86.4%. The MMLU dataset encompasses 57 subjects, including mathematics, physics, history, law, medicine, and ethics, testing the model’s knowledge base and problem-solving abilities.\nUnveiling the DeceptionHowever, only the Gemini Pro version has been made public, with the Gemini Ultra version providing only “learning scores.” The product itself is still in development, and detailed information on parameters is lacking. This lack of transparency gives an impression of both unimpressiveness and a lack of confidence. Shortly after Gemini’s launch on the 6th, netizens pointed out discrepancies in Google’s promotional materials. For instance, when Google claimed that Gemini’s MMLU score surpassed GPT-4, stating GPT-4’s score was 86.4%, the 60-page technical report released by Google had a small footnote for Gemini Ultra’s MMLU test results, mentioning the use of the “CoT@32” prompt technique, attempting 32 times and selecting the best result. In contrast, GPT-4 was evaluated without prompt words, and under this standard, Gemini Ultra’s actual test result was 83.7%, lower than GPT-4’s 86.4%. With the release of the 60-page technical report, fact-checkers started scrutinizing the details.\n\nComparing Gemini’s Chain of Thought results with GPT-4’s few-shot results in multitasking is an unfair assessment. It’s akin to giving Gemini a draft for a math problem, allowing it to use a calculator, while expecting GPT-4 to solve it mentally! Moreover, Gemini had 32 chances to answer, selecting the best one from 32 responses, thanks to CoT@32. If GPT-4 could speak, it might express frustration!\nWhat is Gemini’s true capability without cheating?\nHuggingFace’s Technical Lead, Philipp Schmid, created a new chart — if using 5-shot testing, Gemini’s score is actually 83.7%, not 90.0%.\n\nFacepalm MomentIn terms of video understanding, Gemini indeed demonstrates impressive capabilities, with the demo video showcasing smooth and captivating effects. However, the most astonishing real-time inference effects were achieved through post-editing. As public opinion intensified, Google admitted to editing the video. Originally intended for a grand reveal, it turned into a situation where actions spoke louder than words.\nDiscrepanciesIn most benchmark tests, Gemini Ultra only slightly outperforms OpenAI’s GPT-4 model. In other words, Google’s best AI model made minor improvements on work completed by OpenAI at least a year ago. If Gemini Ultra is released in early January as Google claims, it may not maintain its top-model status for long. During Google’s rush to catch up with OpenAI, the latter has spent nearly a year developing its next-generation artificial intelligence model, GPT-5.\nEvaluationIn the AI field, there are indeed standards for assessing model performance, and different tasks and testing methods can yield different results. However, Google, as a leading figure, surprisingly took such an unscrupulous approach.\nThe video editing and exaggeration of Gemini’s performance may impact public trust in technology. Transparent and objective technical communication is crucial for building trust and driving technological progress.\nThis controversy reflects the fierce competition in the tech industry, where companies may employ various promotional tactics to gain an advantage in the market. It also highlights the ongoing attention and discussion within the tech community regarding new technologies and developments.\n","slug":"What-Gemini-demo-video-is-a-edited-version","date":"2023-12-12T07:11:16.000Z","categories_index":"News","tags_index":"IT news,IT comment,ITFisher.com,Gemini","author_index":"IT Fisher"},{"id":"bc878e746b2ddaee1cd1728c6e28409d","title":"AI, a wave that must be joined","content":"\nYesterday, Google’s big move arrived. On December 6th local time, Google CEO Sundar Pichai officially announced the launch of Gemini 1.0. I believe many people who are following closely have noticed this. When it comes to discussions on the Internet in China and abroad, it’s like two different circles. One key word is layoffs and overseas, while the other is AI.\nAI CompetitionIf you don’t pay special attention to AI, you may miss many key points. Many people think AI equals ChatGPT. What’s so interesting about a chat tool? Answering questions and searching are similar; in China, there’s Baidu’s Wenxin Yiyuan, Xiao Ai, or Siri.\nIf you break out of the information cocoon and look far and wide, you’ll find that things have changed. Now, in the text category, indeed, ChatGPT is dominant, but there are still heavyweight products in other categories. For example, in the image category, there’s Midjourney, which can generate various images based on keywords. Baidu and Alibaba have also launched similar products, such as Alibaba’s Tongyi Wanxiang, but the effects are indeed very different.\nIn the video category, there are products like Pika released last week and Adobe’s Firefly, which can generate interesting videos with just a keyword.\nAI has now expanded from pure text to images, models, and sound in all aspects. It’s not just ChatGPT dominating; it’s a comprehensive development.\nGoogle’s Big Model GeminiTurning back to this big model, the key is multimodal. After training, Gemini 1.0 can simultaneously recognize and understand text, images, audio, etc. Therefore, it can comprehensively understand the details of information in the input and answer questions related to complex topics. Therefore, it is particularly good at reasoning about complex subjects such as mathematics and physics.\nGoogle spared no effort this year, merging Google Brain and DeepMind, finally launching this most powerful and versatile model. There were rumors in March, and it entered the “coming soon” status at the I&#x2F;O conference in May. As the saying goes, good things come to those who wait. Let’s see in January whether it’s bragging or a celebration.\n","slug":"AI-a-wave-that-must-be-joined","date":"2023-12-11T04:11:58.000Z","categories_index":"AI","tags_index":"IT news,IT comment,ITFisher.com","author_index":"IT Fisher"}]